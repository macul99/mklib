{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlayer {\\n  bottom: \"bn1\"\\n  top: \"flatten\"\\n  name: \"fc1_flatten\"\\n  type: \"Flatten\"\\n  flatten_param { axis: 1}\\n}\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go through the original prototxt and prepare a txt file for all the layers to be merged\n",
    "# each line for one set of layers to be merged, the file content should be: conv_name,bn_name,scale_name\n",
    "# eg: /media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_conv_bn_list.txt\n",
    "\n",
    "# copy original prototxt (dgx_train1_31-caffe.prototxt) to a new file name such as dgx_train1_31-caffe-merge-bn.prototxt\n",
    "# modify the new prototxt file, delete corresponding bn and scale layer, and connect output of conv layter to the nex layer of scale layer\n",
    "# for each conv layer, set 'bias_term' to 'true'\n",
    "# for each bn layer, note down the 'eps' value, 'eps' value should be the same for all the bn layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/macul/libraries/mk_utils/mklib/utils')\n",
    "import caffe\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "from caffeMergeBn import caffeMergeBn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stage3_unit11_conv1', 'stage3_unit11_bn2', 'stage3_unit11_bn2_scale')\n",
      "('stage3_unit11_conv2', 'stage3_unit11_bn4', 'stage3_unit11_bn4_scale')\n",
      "('stage3_unit5_conv1', 'stage3_unit5_bn2', 'stage3_unit5_bn2_scale')\n",
      "('stage2_unit2_conv1', 'stage2_unit2_bn2', 'stage2_unit2_bn2_scale')\n",
      "('stage2_unit2_conv2', 'stage2_unit2_bn4', 'stage2_unit2_bn4_scale')\n",
      "('stage4_unit1_convr', 'stage4_unit1_bnr', 'stage4_unit1_bnr_scale')\n",
      "('stage3_unit8_conv2', 'stage3_unit8_bn4', 'stage3_unit8_bn4_scale')\n",
      "('stage3_unit8_conv1', 'stage3_unit8_bn2', 'stage3_unit8_bn2_scale')\n",
      "('stage4_unit1_conv1', 'stage4_unit1_bn2', 'stage4_unit1_bn2_scale')\n",
      "('stage3_unit4_conv2', 'stage3_unit4_bn4', 'stage3_unit4_bn4_scale')\n",
      "('stage3_unit4_conv1', 'stage3_unit4_bn2', 'stage3_unit4_bn2_scale')\n",
      "('stage4_unit1_conv2', 'stage4_unit1_bn4', 'stage4_unit1_bn4_scale')\n",
      "('stage3_unit2_conv1', 'stage3_unit2_bn2', 'stage3_unit2_bn2_scale')\n",
      "('stage3_unit2_conv2', 'stage3_unit2_bn4', 'stage3_unit2_bn4_scale')\n",
      "('stage2_unit4_conv2', 'stage2_unit4_bn4', 'stage2_unit4_bn4_scale')\n",
      "('stage2_unit4_conv1', 'stage2_unit4_bn2', 'stage2_unit4_bn2_scale')\n",
      "('stage3_unit5_conv2', 'stage3_unit5_bn4', 'stage3_unit5_bn4_scale')\n",
      "('stem_conv1', 'stem_bn2', 'stem_bn2_scale')\n",
      "('stage1_unit1_conv1', 'stage1_unit1_bn2', 'stage1_unit1_bn2_scale')\n",
      "('stage1_unit1_conv2', 'stage1_unit1_bn4', 'stage1_unit1_bn4_scale')\n",
      "('stage3_unit13_conv2', 'stage3_unit13_bn4', 'stage3_unit13_bn4_scale')\n",
      "('stage3_unit13_conv1', 'stage3_unit13_bn2', 'stage3_unit13_bn2_scale')\n",
      "('stage3_unit1_convr', 'stage3_unit1_bnr', 'stage3_unit1_bnr_scale')\n",
      "('stage2_unit1_convr', 'stage2_unit1_bnr', 'stage2_unit1_bnr_scale')\n",
      "('stage3_unit6_conv2', 'stage3_unit6_bn4', 'stage3_unit6_bn4_scale')\n",
      "('stage3_unit14_conv1', 'stage3_unit14_bn2', 'stage3_unit14_bn2_scale')\n",
      "('stage4_unit2_conv2', 'stage4_unit2_bn4', 'stage4_unit2_bn4_scale')\n",
      "('stage3_unit14_conv2', 'stage3_unit14_bn4', 'stage3_unit14_bn4_scale')\n",
      "('stage2_unit3_conv1', 'stage2_unit3_bn2', 'stage2_unit3_bn2_scale')\n",
      "('stage3_unit3_conv1', 'stage3_unit3_bn2', 'stage3_unit3_bn2_scale')\n",
      "('stage3_unit3_conv2', 'stage3_unit3_bn4', 'stage3_unit3_bn4_scale')\n",
      "('stage2_unit3_conv2', 'stage2_unit3_bn4', 'stage2_unit3_bn4_scale')\n",
      "('stage4_unit3_conv2', 'stage4_unit3_bn4', 'stage4_unit3_bn4_scale')\n",
      "('stage4_unit3_conv1', 'stage4_unit3_bn2', 'stage4_unit3_bn2_scale')\n",
      "('stage4_unit2_conv1', 'stage4_unit2_bn2', 'stage4_unit2_bn2_scale')\n",
      "('stage3_unit9_conv2', 'stage3_unit9_bn4', 'stage3_unit9_bn4_scale')\n",
      "('stage3_unit9_conv1', 'stage3_unit9_bn2', 'stage3_unit9_bn2_scale')\n",
      "('stage3_unit10_conv1', 'stage3_unit10_bn2', 'stage3_unit10_bn2_scale')\n",
      "('stage3_unit12_conv2', 'stage3_unit12_bn4', 'stage3_unit12_bn4_scale')\n",
      "('stage3_unit12_conv1', 'stage3_unit12_bn2', 'stage3_unit12_bn2_scale')\n",
      "('stage3_unit7_conv1', 'stage3_unit7_bn2', 'stage3_unit7_bn2_scale')\n",
      "('stage3_unit7_conv2', 'stage3_unit7_bn4', 'stage3_unit7_bn4_scale')\n",
      "('out_conv1', 'out_bn3', 'out_bn3_scale')\n",
      "('stage1_unit2_conv2', 'stage1_unit2_bn4', 'stage1_unit2_bn4_scale')\n",
      "('stage1_unit2_conv1', 'stage1_unit2_bn2', 'stage1_unit2_bn2_scale')\n",
      "('stage3_unit6_conv1', 'stage3_unit6_bn2', 'stage3_unit6_bn2_scale')\n",
      "('stage3_unit10_conv2', 'stage3_unit10_bn4', 'stage3_unit10_bn4_scale')\n",
      "('stage1_unit1_convr', 'stage1_unit1_bnr', 'stage1_unit1_bnr_scale')\n",
      "('stage1_unit3_conv2', 'stage1_unit3_bn4', 'stage1_unit3_bn4_scale')\n",
      "('stage1_unit3_conv1', 'stage1_unit3_bn2', 'stage1_unit3_bn2_scale')\n",
      "('stage3_unit1_conv2', 'stage3_unit1_bn4', 'stage3_unit1_bn4_scale')\n",
      "('stage2_unit1_conv2', 'stage2_unit1_bn4', 'stage2_unit1_bn4_scale')\n",
      "('stage2_unit1_conv1', 'stage2_unit1_bn2', 'stage2_unit1_bn2_scale')\n",
      "('stage3_unit1_conv1', 'stage3_unit1_bn2', 'stage3_unit1_bn2_scale')\n"
     ]
    }
   ],
   "source": [
    "#train_proto='/media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_31-caffe.prototxt' # original prototxt\n",
    "#train_model='/media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_31-caffe.caffemodel' # original caffe model\n",
    "#deploy_proto='/media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_31-caffe-merge-bn.prototxt' # new prototxt file\n",
    "#save_model='/media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_31-caffe-merge-bn.caffemodel' # output model file name to be saved\n",
    "#conv_bn_list='/media/macul/black/mxnet_training/r50/dgx_train1/dgx_train1_conv_bn_list.txt' # layer pair txt file\n",
    "train_proto='/media/macul/black/mxnet_training/r50/server_train18/server_train18-caffe.prototxt' # original prototxt\n",
    "train_model='/media/macul/black/mxnet_training/r50/server_train18/server_train18_6062-caffe.caffemodel' # original caffe model\n",
    "deploy_proto='/media/macul/black/mxnet_training/r50/server_train18/server_train18-caffe-merge-bn.prototxt' # new prototxt file\n",
    "save_model='/media/macul/black/mxnet_training/r50/server_train18/server_train18_6062-caffe-merge-bn.caffemodel' # output model file name to be saved\n",
    "conv_bn_list='/media/macul/black/mxnet_training/r50/server_train18/server_train18_conv_bn_list.txt' # layer pair txt file\n",
    "EPS=2e-5 # should match the bn layer eps value from the original prototxt\n",
    "\n",
    "cm = caffeMergeBn(train_proto,train_model,deploy_proto,save_model,conv_bn_list,EPS)\n",
    "cm.merge_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path /media/macul/black/mxnet_training/r50/server_train18\n",
      "prototxt_name server_train18-caffe-merge-bn\n",
      "(512,)\n",
      "model_path /media/macul/black/mxnet_training/r50/server_train18\n",
      "prototxt_name server_train18-caffe\n",
      "(512,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from caffeFeatureExtract import caffeFeatureExtract\n",
    "#a=caffeFeatureExtract('/media/macul/black/mxnet_training/r50/dgx_train1',prototxt_name='dgx_train1_31-caffe-merge-bn',caffemodel_name='dgx_train1_31-caffe-merge-bn',outputs_name={'embedding':'out_embedding'})\n",
    "#embedding=a.getEmbedding('/media/macul/black/face_database_raw_data/mscelb_from_insightface/Data/0000000/0000.png')\n",
    "#a1=caffeFeatureExtract('/media/macul/black/mxnet_training/r50/dgx_train1',prototxt_name='dgx_train1_31-caffe',caffemodel_name='dgx_train1_31-caffe',outputs_name={'embedding':'out_embedding'})\n",
    "#embedding1=a1.getEmbedding('/media/macul/black/face_database_raw_data/mscelb_from_insightface/Data/0000000/0000.png')\n",
    "a=caffeFeatureExtract('/media/macul/black/mxnet_training/r50/server_train18',prototxt_name='server_train18-caffe-merge-bn',caffemodel_name='server_train18_6062-caffe-merge-bn',outputs_name={'embedding':'out_embedding'})\n",
    "embedding=a.getEmbedding('/media/macul/black/face_database_raw_data/mscelb_from_insightface/Data/0000000/0000.png')\n",
    "a1=caffeFeatureExtract('/media/macul/black/mxnet_training/r50/server_train18',prototxt_name='server_train18-caffe',caffemodel_name='server_train18_6062-caffe',outputs_name={'embedding':'out_embedding'})\n",
    "embedding1=a1.getEmbedding('/media/macul/black/face_database_raw_data/mscelb_from_insightface/Data/0000000/0000.png')\n",
    "np.dot(embedding,embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

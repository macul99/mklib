{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/macul/libraries/mk_utils/mklib/nn/tfnet/')\n",
    "sys.path.append('/home/macul/libraries/mk_utils/mklib/nn/tfloss/')\n",
    "sys.path.append('/home/macul/libraries/mk_utils/tf_spoof/')\n",
    "sys.path.append('/home/macul/libraries/mk_utils/spoofing_lbp/')\n",
    "from config import net_config as config\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from os.path import isdir\n",
    "from os import mkdir\n",
    "from shutil import copyfile\n",
    "from spoof_feature import LBP_GREY, LBP_RG, CoALBP, CoALBP_256, CoALBP_GREY, BSIF, LPQ, COLOR_MOMENT\n",
    "from tfspoofdense import SpoofDenseNet\n",
    "from tfloss import TfLosses\n",
    "import time\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "Model_Process = {'BSIF'        : BSIF(),\n",
    "                 'CoALBP'      : CoALBP(),\n",
    "                 'CoALBP_GREY' : CoALBP_GREY(),\n",
    "                 'CoALBP_256'  : CoALBP_256(),\n",
    "                 'COLOR_MOMENT': COLOR_MOMENT(),\n",
    "                 'LBP_GREY'    : LBP_GREY(),\n",
    "                 'LBP_RG'      : LBP_RG(),\n",
    "                 'LPQ'         : LPQ(),\n",
    "                }\n",
    "\n",
    "# get ft extractor and network configuration\n",
    "ft_extractor = [Model_Process[ex] for ex in config.Feature_Type]\n",
    "ft_layer_units = [config.Dense_Cfg[ex] for ex in config.Feature_Type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.DEVICE_IDS\n",
    "#batchSize = config.BATCH_SIZE * config.NUM_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_crop_shuffle(img, height, width, grid_size=4):\n",
    "    crop_h = tf.cast(height/4,tf.int32)\n",
    "    crop_w = tf.cast(width/4,tf.int32)\n",
    "    \n",
    "    idx = list(range(grid_size*grid_size))\n",
    "    np.random.shuffle(idx)\n",
    "    img_tmp = []\n",
    "    cnt = 0\n",
    "    for i, v in enumerate(idx):\n",
    "        if i%grid_size == 0:\n",
    "            img_crop = tf.image.crop_to_bounding_box(img, int(idx[i]/4)*crop_h,int(idx[i]%4)*crop_w,crop_h,crop_w)\n",
    "        else:\n",
    "            img_crop = tf.concat([img_crop, tf.image.crop_to_bounding_box(img, int(idx[i]/4)*crop_h,int(idx[i]%4)*crop_w,crop_h,crop_w)], 1)\n",
    "        cnt += 1\n",
    "        if cnt == grid_size:\n",
    "            img_tmp += [img_crop]\n",
    "            cnt = 0\n",
    "    img1 = img_tmp[0]\n",
    "    for i in range(1,len(img_tmp)):\n",
    "        img1 = tf.concat([img1,img_tmp[i]],0)\n",
    "        \n",
    "    return img1\n",
    "\n",
    "\n",
    "# this function must be used for batch_size of 1 or before batch operation since the image size varies\n",
    "def parse_function(example_proto, grid_size=4):\n",
    "    \n",
    "    features = {'image/encoded': tf.FixedLenFeature([], tf.string),\n",
    "                'image/height': tf.FixedLenFeature([], tf.int64),\n",
    "                'image/width': tf.FixedLenFeature([], tf.int64),\n",
    "                #'image/colorspace': tf.FixedLenFeature([], tf.string),\n",
    "                #'image/channels': tf.FixedLenFeature([], tf.int64),\n",
    "                #'image/class/text': tf.FixedLenFeature([], tf.string),\n",
    "                'image/class/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    \n",
    "    features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    img = tf.image.decode_jpeg(features['image/encoded'])\n",
    "    #img = features['image/encoded']\n",
    "    \n",
    "    # img = tf.reshape(img, shape=(112, 112, 3))\n",
    "    # r, g, b = tf.split(img, num_or_size_splits=3, axis=-1)\n",
    "    # img = tf.concat([b, g, r], axis=-1)\n",
    "    \n",
    "    #img = tf.cast(img, dtype=tf.float32)\n",
    "    #img = tf.subtract(img, 127.5)\n",
    "    #img = tf.multiply(img,  0.0078125)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    \n",
    "    label = tf.cast(features['image/class/label'], tf.int64) - 1\n",
    "    \n",
    "    if grid_size <= 1:\n",
    "        return img, label\n",
    "    \n",
    "    height = tf.cast(features['image/height'], tf.int64)\n",
    "    width = tf.cast(features['image/width'], tf.int64)\n",
    "    \n",
    "    return img_crop_shuffle(img,height,width,grid_size), label\n",
    "\n",
    "def feature_extraction(img, extractor):\n",
    "    ft = []\n",
    "    for ex in extractor:\n",
    "        ft += [tf.cast(tf.py_func(ex, [img], tf.double),tf.float32)]\n",
    "    return tuple(ft) # list does not work here, need to convert to tuple\n",
    "    #return tuple(ft), img # for dataset debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# dataset testing\\ndataset_train = tf.data.TFRecordDataset(config.TRAIN_REC)\\n\\n#for raw_record in dataset_train.take(1):\\n#    print(repr(raw_record))\\n\\ndataset_train = dataset_train.map(lambda x: parse_function(x, config.Img_shuffle_grid_size))\\n#dataset_train = dataset_train.shuffle(buffer_size=config.BUFFER_SIZE) # shuffle the whole dataset is better\\n#dataset_train = dataset_train.batch(1)\\n#dataset_train = dataset_train.apply(tf.data.experimental.unbatch())\\ndataset_train = dataset_train.map(lambda *x: (feature_extraction(x[0], ft_extractor), x[1]))\\ndataset_train = dataset_train.batch(4)\\niterator_train = dataset_train.make_initializable_iterator()\\nnext_element_train = iterator_train.get_next()\\n\\ncfg = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\\ncfg.gpu_options.allow_growth = True\\n\\nsess = tf.Session(config=cfg)\\nsess.run(iterator_train.initializer)\\n\\nfeature, label = sess.run(next_element_train)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# dataset testing\n",
    "dataset_train = tf.data.TFRecordDataset(config.TRAIN_REC)\n",
    "\n",
    "#for raw_record in dataset_train.take(1):\n",
    "#    print(repr(raw_record))\n",
    "\n",
    "dataset_train = dataset_train.map(lambda x: parse_function(x, config.Img_shuffle_grid_size))\n",
    "#dataset_train = dataset_train.shuffle(buffer_size=config.BUFFER_SIZE) # shuffle the whole dataset is better\n",
    "#dataset_train = dataset_train.batch(1)\n",
    "#dataset_train = dataset_train.apply(tf.data.experimental.unbatch())\n",
    "dataset_train = dataset_train.map(lambda *x: (feature_extraction(x[0], ft_extractor), x[1]))\n",
    "dataset_train = dataset_train.batch(4)\n",
    "iterator_train = dataset_train.make_initializable_iterator()\n",
    "next_element_train = iterator_train.get_next()\n",
    "\n",
    "cfg = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "cfg.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=cfg)\n",
    "sess.run(iterator_train.initializer)\n",
    "\n",
    "feature, label = sess.run(next_element_train)\n",
    "'''\n",
    "\n",
    "#training_ph = tf.placeholder(name='training_flag',shape=[], dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_scope = 'SpoofDenseNet'\n",
    "\n",
    "# declare placeholders\n",
    "labels_ph = tf.placeholder(name='label',shape=[None,], dtype=tf.int64)\n",
    "features_ph = tuple([tf.placeholder(name='ft_{}'.format(f_key),shape=[None,config.Feature_Size[f_key]], \n",
    "                                    dtype=tf.float32) for f_key in config.Feature_Type])\n",
    "# build training dataset and network\n",
    "dataset_train = tf.data.TFRecordDataset(config.TRAIN_REC)\n",
    "dataset_train = dataset_train.map(lambda x: parse_function(x, config.Img_shuffle_grid_size))\n",
    "dataset_train = dataset_train.shuffle(buffer_size=config.BUFFER_SIZE) # shuffle the whole dataset is better\n",
    "dataset_train = dataset_train.map(lambda *x: (feature_extraction(x[0], ft_extractor), x[1]))\n",
    "# remember to set batch size to 1 for dataset debug\n",
    "#dataset_train = dataset_train.map(lambda *x: feature_extraction(x[0], ft_extractor) + (x[1],)) # for dataset debug\n",
    "dataset_train = dataset_train.batch(config.BATCH_SIZE)\n",
    "iterator_train = dataset_train.make_initializable_iterator()\n",
    "next_element_train = iterator_train.get_next()\n",
    "with tf.variable_scope(net_scope):\n",
    "    # build base network\n",
    "    embeddings = SpoofDenseNet.build(features_ph, feature_units=ft_layer_units, stem_units=config.Dense_Stem_Cfg, \n",
    "                                     training=True, act=config.Activation, reg=config.Regularizer, \n",
    "                                     init=config.Initializer, scope='spoof')\n",
    "    #logit, inference_loss = TfLosses.softmax_loss(embedding=embeddings, labels=labels_ph, out_num=config.NUM_CLASSES,  \n",
    "    #                                              act=config.Activation, reg=config.Regularizer, \n",
    "    #                                              init=config.Initializer)\n",
    "    logit, inference_loss = TfLosses.arc_loss(embedding=embeddings, labels=labels_ph, w_init=config.Initializer, \n",
    "                                              out_num=config.NUM_CLASSES, s=config.Arc_margin_scale, \n",
    "                                              m=config.Arc_margin_angle)\n",
    "    pred = tf.nn.softmax(logit)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, axis=1), labels_ph), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "global_step = tf.Variable(name='global_step', initial_value=0, trainable=False)\n",
    "inc_op = tf.assign_add(global_step, 1, name='increment_global_step')\n",
    "lr = tf.train.piecewise_constant(global_step, boundaries=config.Opt_lr_steps, values=config.Opt_lr, name='lr_schedule')\n",
    "# define the optimize method\n",
    "opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=config.Opt_momentum)\n",
    "# get train op\n",
    "#grads = opt.compute_gradients(inference_loss)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):        \n",
    "    #train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "    train_op = opt.minimize(inference_loss, global_step=global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare placeholders\n",
    "labels_val_ph = tf.placeholder(name='label',shape=[None,], dtype=tf.int64)\n",
    "features_val_ph = tuple([tf.placeholder(name='ft_{}'.format(f_key),shape=[None,config.Feature_Size[f_key]], \n",
    "                                    dtype=tf.float32) for f_key in config.Feature_Type])\n",
    "# build validation dataset and network\n",
    "dataset_val = tf.data.TFRecordDataset(config.VAL_REC)\n",
    "dataset_val = dataset_val.map(lambda x: parse_function(x, 0))\n",
    "dataset_val = dataset_val.map(lambda *x: (feature_extraction(x[0], ft_extractor), x[1]))\n",
    "dataset_val = dataset_val.batch(config.BATCH_SIZE)\n",
    "iterator_val = dataset_val.make_initializable_iterator()\n",
    "next_element_val = iterator_val.get_next()\n",
    "with tf.variable_scope(net_scope, reuse=True):\n",
    "    # build base network\n",
    "    embeddings_val = SpoofDenseNet.build(features_val_ph, feature_units=ft_layer_units, stem_units=config.Dense_Stem_Cfg, \n",
    "                                         training=False, act=config.Activation, reg=config.Regularizer, \n",
    "                                         init=config.Initializer, scope='spoof')\n",
    "    logit_val, _ = TfLosses.arc_loss(embedding=embeddings_val, labels=labels_val_ph, w_init=config.Initializer, \n",
    "                                     out_num=config.NUM_CLASSES, s=config.Arc_margin_scale, m=0)\n",
    "    pred_val = tf.nn.softmax(logit_val)\n",
    "    acc_val = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred_val, axis=1), labels_val_ph), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create session\n",
    "cfg = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "cfg.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=cfg)\n",
    "# create model saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "time_stamp = time.strftime('_%Y-%m-%d-%H-%M', time.localtime(time.time()))\n",
    "\n",
    "# create output folder\n",
    "checkpointsPath = os.path.sep.join([config.OUT_PATH, config.PREFIX])\n",
    "if not isdir(checkpointsPath):\n",
    "    mkdir(checkpointsPath)\n",
    "    \n",
    "# define log file\n",
    "log_file_path = checkpointsPath + '/train' + time_stamp + '.log'\n",
    "log_file = open(log_file_path, 'w')\n",
    "\n",
    "# summary writer\n",
    "summary = tf.summary.FileWriter(checkpointsPath, sess.graph)\n",
    "summaries = []\n",
    "# trainabel variable gradients\n",
    "for var in tf.trainable_variables():\n",
    "    summaries.append(tf.summary.histogram(var.op.name, var))\n",
    "# add loss summary\n",
    "summaries.append(tf.summary.scalar('inference_loss', inference_loss))\n",
    "# add learning rate\n",
    "summaries.append(tf.summary.scalar('leraning_rate', lr))\n",
    "# add accuracy\n",
    "summaries.append(tf.summary.scalar('accuracy', acc))\n",
    "summary_op = tf.summary.merge(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 0, total_step 10, inference loss is 6.63, accuracy is 0.390625, time 313.202 samples/sec\n",
      "Training: epoch 0, total_step 20, inference loss is 4.69, accuracy is 0.453125, time 295.324 samples/sec\n",
      "Training: epoch 0, total_step 30, inference loss is 3.50, accuracy is 0.468750, time 310.603 samples/sec\n",
      "Training: epoch 0, total_step 40, inference loss is 2.66, accuracy is 0.429688, time 310.280 samples/sec\n",
      "Training: epoch 0, total_step 50, inference loss is 1.61, accuracy is 0.484375, time 315.851 samples/sec\n",
      "Training: epoch 0, total_step 60, inference loss is 1.42, accuracy is 0.437500, time 312.414 samples/sec\n",
      "Training: epoch 0, total_step 70, inference loss is 1.05, accuracy is 0.507812, time 307.085 samples/sec\n",
      "Training: epoch 0, total_step 80, inference loss is 0.98, accuracy is 0.539062, time 311.877 samples/sec\n",
      "Training: epoch 0, total_step 90, inference loss is 0.95, accuracy is 0.539062, time 296.226 samples/sec\n",
      "Training: epoch 0, total_step 100, inference loss is 0.95, accuracy is 0.593750, time 302.444 samples/sec\n",
      "Training: epoch 0, total_step 110, inference loss is 0.99, accuracy is 0.546875, time 309.338 samples/sec\n",
      "Training: epoch 0, total_step 120, inference loss is 0.98, accuracy is 0.515625, time 304.440 samples/sec\n",
      "Training: epoch 0, total_step 130, inference loss is 0.98, accuracy is 0.539062, time 299.817 samples/sec\n",
      "Training: epoch 0, total_step 140, inference loss is 1.02, accuracy is 0.554688, time 300.808 samples/sec\n",
      "Training: epoch 0, total_step 150, inference loss is 0.94, accuracy is 0.585938, time 308.254 samples/sec\n",
      "Training: epoch 0, total_step 160, inference loss is 0.99, accuracy is 0.460938, time 314.481 samples/sec\n",
      "Training: epoch 0, total_step 170, inference loss is 0.89, accuracy is 0.632812, time 317.301 samples/sec\n",
      "Training: epoch 0, total_step 180, inference loss is 0.90, accuracy is 0.500000, time 297.185 samples/sec\n",
      "Training: epoch 0, total_step 190, inference loss is 0.98, accuracy is 0.484375, time 314.290 samples/sec\n",
      "Training: epoch 0, total_step 200, inference loss is 1.02, accuracy is 0.515625, time 299.608 samples/sec\n",
      "Training: epoch 0, total_step 210, inference loss is 0.93, accuracy is 0.523438, time 303.057 samples/sec\n",
      "Training: epoch 0, total_step 220, inference loss is 0.93, accuracy is 0.562500, time 292.494 samples/sec\n",
      "Training: epoch 0, total_step 230, inference loss is 0.85, accuracy is 0.617188, time 295.701 samples/sec\n",
      "Training: epoch 0, total_step 240, inference loss is 0.97, accuracy is 0.546875, time 308.226 samples/sec\n",
      "Training: epoch 0, total_step 250, inference loss is 0.98, accuracy is 0.585938, time 302.106 samples/sec\n",
      "Training: epoch 0, total_step 260, inference loss is 1.00, accuracy is 0.554688, time 314.180 samples/sec\n",
      "Training: epoch 0, total_step 270, inference loss is 1.01, accuracy is 0.585938, time 295.497 samples/sec\n",
      "Training: epoch 0, total_step 280, inference loss is 0.86, accuracy is 0.656250, time 319.665 samples/sec\n",
      "Training: epoch 0, total_step 290, inference loss is 0.91, accuracy is 0.562500, time 305.943 samples/sec\n",
      "Training: epoch 0, total_step 300, inference loss is 0.87, accuracy is 0.554688, time 309.668 samples/sec\n",
      "Training: epoch 0, total_step 310, inference loss is 1.01, accuracy is 0.523438, time 313.982 samples/sec\n",
      "Training: epoch 0, total_step 320, inference loss is 0.98, accuracy is 0.523438, time 303.156 samples/sec\n",
      "Training: epoch 0, total_step 330, inference loss is 0.94, accuracy is 0.562500, time 313.098 samples/sec\n",
      "Training: epoch 0, total_step 340, inference loss is 0.91, accuracy is 0.593750, time 294.668 samples/sec\n",
      "Training: epoch 0, total_step 350, inference loss is 0.90, accuracy is 0.570312, time 307.093 samples/sec\n",
      "Training: epoch 0, total_step 360, inference loss is 1.01, accuracy is 0.554688, time 306.330 samples/sec\n",
      "Training: epoch 0, total_step 370, inference loss is 0.83, accuracy is 0.617188, time 307.137 samples/sec\n",
      "Training: epoch 0, total_step 380, inference loss is 0.96, accuracy is 0.585938, time 310.823 samples/sec\n",
      "End of epoch 0\n",
      "$$$$$$$$ Validation: epoch 0, accuracy is 0.723477\n",
      "Training: epoch 1, total_step 390, inference loss is 0.94, accuracy is 0.570312, time 293.573 samples/sec\n",
      "Training: epoch 1, total_step 400, inference loss is 0.88, accuracy is 0.593750, time 293.318 samples/sec\n",
      "Training: epoch 1, total_step 410, inference loss is 0.90, accuracy is 0.593750, time 299.728 samples/sec\n",
      "Training: epoch 1, total_step 420, inference loss is 0.84, accuracy is 0.664062, time 298.780 samples/sec\n",
      "Training: epoch 1, total_step 430, inference loss is 0.88, accuracy is 0.593750, time 304.832 samples/sec\n",
      "Training: epoch 1, total_step 440, inference loss is 0.99, accuracy is 0.562500, time 289.896 samples/sec\n",
      "Training: epoch 1, total_step 450, inference loss is 0.96, accuracy is 0.578125, time 308.558 samples/sec\n",
      "Training: epoch 1, total_step 460, inference loss is 1.00, accuracy is 0.523438, time 307.842 samples/sec\n",
      "Training: epoch 1, total_step 470, inference loss is 1.01, accuracy is 0.585938, time 297.072 samples/sec\n",
      "Training: epoch 1, total_step 480, inference loss is 1.00, accuracy is 0.515625, time 301.127 samples/sec\n",
      "Training: epoch 1, total_step 490, inference loss is 1.08, accuracy is 0.468750, time 298.460 samples/sec\n",
      "Training: epoch 1, total_step 500, inference loss is 1.00, accuracy is 0.609375, time 294.825 samples/sec\n",
      "Training: epoch 1, total_step 510, inference loss is 0.93, accuracy is 0.625000, time 297.112 samples/sec\n",
      "Training: epoch 1, total_step 520, inference loss is 0.94, accuracy is 0.570312, time 309.649 samples/sec\n",
      "Training: epoch 1, total_step 530, inference loss is 0.96, accuracy is 0.554688, time 270.735 samples/sec\n",
      "Training: epoch 1, total_step 540, inference loss is 0.93, accuracy is 0.601562, time 294.070 samples/sec\n",
      "Training: epoch 1, total_step 550, inference loss is 0.91, accuracy is 0.609375, time 303.493 samples/sec\n",
      "Training: epoch 1, total_step 560, inference loss is 1.00, accuracy is 0.562500, time 302.901 samples/sec\n",
      "Training: epoch 1, total_step 570, inference loss is 1.01, accuracy is 0.515625, time 296.500 samples/sec\n",
      "Training: epoch 1, total_step 580, inference loss is 0.98, accuracy is 0.539062, time 303.866 samples/sec\n",
      "Training: epoch 1, total_step 590, inference loss is 0.91, accuracy is 0.562500, time 311.502 samples/sec\n",
      "Training: epoch 1, total_step 600, inference loss is 0.91, accuracy is 0.601562, time 297.813 samples/sec\n",
      "Training: epoch 1, total_step 610, inference loss is 0.92, accuracy is 0.570312, time 291.746 samples/sec\n",
      "Training: epoch 1, total_step 620, inference loss is 0.90, accuracy is 0.601562, time 292.996 samples/sec\n",
      "Training: epoch 1, total_step 630, inference loss is 0.82, accuracy is 0.648438, time 303.963 samples/sec\n",
      "Training: epoch 1, total_step 640, inference loss is 0.89, accuracy is 0.617188, time 298.222 samples/sec\n",
      "Training: epoch 1, total_step 650, inference loss is 0.85, accuracy is 0.625000, time 300.964 samples/sec\n",
      "Training: epoch 1, total_step 660, inference loss is 0.93, accuracy is 0.570312, time 301.867 samples/sec\n",
      "Training: epoch 1, total_step 670, inference loss is 0.95, accuracy is 0.554688, time 276.040 samples/sec\n",
      "Training: epoch 1, total_step 680, inference loss is 0.88, accuracy is 0.640625, time 293.371 samples/sec\n",
      "Training: epoch 1, total_step 690, inference loss is 0.93, accuracy is 0.578125, time 271.879 samples/sec\n",
      "Training: epoch 1, total_step 700, inference loss is 0.87, accuracy is 0.632812, time 303.275 samples/sec\n",
      "Training: epoch 1, total_step 710, inference loss is 0.88, accuracy is 0.601562, time 286.788 samples/sec\n",
      "Training: epoch 1, total_step 720, inference loss is 0.89, accuracy is 0.617188, time 295.138 samples/sec\n",
      "Training: epoch 1, total_step 730, inference loss is 0.90, accuracy is 0.562500, time 304.529 samples/sec\n",
      "Training: epoch 1, total_step 740, inference loss is 0.90, accuracy is 0.562500, time 301.452 samples/sec\n",
      "Training: epoch 1, total_step 750, inference loss is 0.87, accuracy is 0.585938, time 277.095 samples/sec\n",
      "Training: epoch 1, total_step 760, inference loss is 0.97, accuracy is 0.546875, time 312.542 samples/sec\n",
      "Training: epoch 1, total_step 770, inference loss is 0.96, accuracy is 0.562500, time 312.271 samples/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1\n",
      "$$$$$$$$ Validation: epoch 1, accuracy is 0.708231\n",
      "Training: epoch 2, total_step 780, inference loss is 0.88, accuracy is 0.625000, time 281.982 samples/sec\n",
      "Training: epoch 2, total_step 790, inference loss is 0.89, accuracy is 0.648438, time 290.850 samples/sec\n",
      "Training: epoch 2, total_step 800, inference loss is 0.86, accuracy is 0.625000, time 297.966 samples/sec\n",
      "Training: epoch 2, total_step 810, inference loss is 0.81, accuracy is 0.671875, time 290.259 samples/sec\n",
      "Training: epoch 2, total_step 820, inference loss is 0.72, accuracy is 0.765625, time 280.049 samples/sec\n",
      "Training: epoch 2, total_step 830, inference loss is 0.90, accuracy is 0.578125, time 294.991 samples/sec\n",
      "Training: epoch 2, total_step 840, inference loss is 0.92, accuracy is 0.601562, time 296.708 samples/sec\n",
      "Training: epoch 2, total_step 850, inference loss is 0.88, accuracy is 0.585938, time 299.805 samples/sec\n",
      "Training: epoch 2, total_step 860, inference loss is 0.97, accuracy is 0.531250, time 299.610 samples/sec\n",
      "Training: epoch 2, total_step 870, inference loss is 0.90, accuracy is 0.585938, time 297.106 samples/sec\n",
      "Training: epoch 2, total_step 880, inference loss is 0.89, accuracy is 0.585938, time 294.470 samples/sec\n",
      "Training: epoch 2, total_step 890, inference loss is 0.86, accuracy is 0.656250, time 289.930 samples/sec\n",
      "Training: epoch 2, total_step 900, inference loss is 0.92, accuracy is 0.601562, time 278.803 samples/sec\n",
      "Training: epoch 2, total_step 910, inference loss is 0.86, accuracy is 0.609375, time 280.504 samples/sec\n",
      "Training: epoch 2, total_step 920, inference loss is 0.85, accuracy is 0.609375, time 296.905 samples/sec\n",
      "Training: epoch 2, total_step 930, inference loss is 0.98, accuracy is 0.554688, time 299.807 samples/sec\n",
      "Training: epoch 2, total_step 940, inference loss is 0.99, accuracy is 0.492188, time 292.550 samples/sec\n",
      "Training: epoch 2, total_step 950, inference loss is 0.83, accuracy is 0.617188, time 297.543 samples/sec\n",
      "Training: epoch 2, total_step 960, inference loss is 0.89, accuracy is 0.593750, time 294.018 samples/sec\n",
      "Training: epoch 2, total_step 970, inference loss is 0.86, accuracy is 0.656250, time 304.807 samples/sec\n",
      "Training: epoch 2, total_step 980, inference loss is 0.82, accuracy is 0.671875, time 296.062 samples/sec\n",
      "Training: epoch 2, total_step 990, inference loss is 0.84, accuracy is 0.625000, time 301.200 samples/sec\n",
      "Training: epoch 2, total_step 1000, inference loss is 0.81, accuracy is 0.625000, time 298.240 samples/sec\n",
      "Training: epoch 2, total_step 1010, inference loss is 0.92, accuracy is 0.601562, time 303.951 samples/sec\n",
      "Training: epoch 2, total_step 1020, inference loss is 0.93, accuracy is 0.578125, time 291.238 samples/sec\n",
      "Training: epoch 2, total_step 1030, inference loss is 0.86, accuracy is 0.632812, time 289.183 samples/sec\n",
      "Training: epoch 2, total_step 1040, inference loss is 0.82, accuracy is 0.632812, time 311.971 samples/sec\n",
      "Training: epoch 2, total_step 1050, inference loss is 0.92, accuracy is 0.601562, time 296.072 samples/sec\n",
      "Training: epoch 2, total_step 1060, inference loss is 0.91, accuracy is 0.609375, time 295.472 samples/sec\n",
      "Training: epoch 2, total_step 1070, inference loss is 0.87, accuracy is 0.601562, time 293.113 samples/sec\n",
      "Training: epoch 2, total_step 1080, inference loss is 0.88, accuracy is 0.601562, time 286.971 samples/sec\n",
      "Training: epoch 2, total_step 1090, inference loss is 0.90, accuracy is 0.617188, time 297.831 samples/sec\n",
      "Training: epoch 2, total_step 1100, inference loss is 0.88, accuracy is 0.617188, time 304.273 samples/sec\n",
      "Training: epoch 2, total_step 1110, inference loss is 0.85, accuracy is 0.617188, time 295.048 samples/sec\n",
      "Training: epoch 2, total_step 1120, inference loss is 0.91, accuracy is 0.617188, time 294.836 samples/sec\n",
      "Training: epoch 2, total_step 1130, inference loss is 0.92, accuracy is 0.539062, time 287.495 samples/sec\n",
      "Training: epoch 2, total_step 1140, inference loss is 0.82, accuracy is 0.648438, time 263.460 samples/sec\n",
      "Training: epoch 2, total_step 1150, inference loss is 1.04, accuracy is 0.570312, time 295.397 samples/sec\n",
      "Training: epoch 2, total_step 1160, inference loss is 0.93, accuracy is 0.554688, time 295.268 samples/sec\n",
      "End of epoch 2\n",
      "$$$$$$$$ Validation: epoch 2, accuracy is 0.716044\n",
      "Training: epoch 3, total_step 1170, inference loss is 0.92, accuracy is 0.570312, time 298.529 samples/sec\n",
      "Training: epoch 3, total_step 1180, inference loss is 0.82, accuracy is 0.656250, time 282.258 samples/sec\n",
      "Training: epoch 3, total_step 1190, inference loss is 1.04, accuracy is 0.539062, time 296.475 samples/sec\n",
      "Training: epoch 3, total_step 1200, inference loss is 0.98, accuracy is 0.601562, time 294.673 samples/sec\n",
      "Training: epoch 3, total_step 1210, inference loss is 0.86, accuracy is 0.617188, time 301.530 samples/sec\n",
      "Training: epoch 3, total_step 1220, inference loss is 0.91, accuracy is 0.585938, time 293.678 samples/sec\n",
      "Training: epoch 3, total_step 1230, inference loss is 0.87, accuracy is 0.609375, time 293.632 samples/sec\n",
      "Training: epoch 3, total_step 1240, inference loss is 0.84, accuracy is 0.625000, time 294.895 samples/sec\n",
      "Training: epoch 3, total_step 1250, inference loss is 0.97, accuracy is 0.578125, time 301.767 samples/sec\n",
      "Training: epoch 3, total_step 1260, inference loss is 0.90, accuracy is 0.609375, time 298.567 samples/sec\n",
      "Training: epoch 3, total_step 1270, inference loss is 0.91, accuracy is 0.601562, time 290.006 samples/sec\n",
      "Training: epoch 3, total_step 1280, inference loss is 0.83, accuracy is 0.625000, time 306.667 samples/sec\n",
      "Training: epoch 3, total_step 1290, inference loss is 0.84, accuracy is 0.656250, time 301.206 samples/sec\n",
      "Training: epoch 3, total_step 1300, inference loss is 0.88, accuracy is 0.617188, time 296.907 samples/sec\n",
      "Training: epoch 3, total_step 1310, inference loss is 0.99, accuracy is 0.554688, time 294.846 samples/sec\n",
      "Training: epoch 3, total_step 1320, inference loss is 0.86, accuracy is 0.585938, time 307.532 samples/sec\n",
      "Training: epoch 3, total_step 1330, inference loss is 0.79, accuracy is 0.695312, time 310.938 samples/sec\n",
      "Training: epoch 3, total_step 1340, inference loss is 0.87, accuracy is 0.601562, time 298.437 samples/sec\n",
      "Training: epoch 3, total_step 1350, inference loss is 0.96, accuracy is 0.523438, time 300.054 samples/sec\n",
      "Training: epoch 3, total_step 1360, inference loss is 0.88, accuracy is 0.648438, time 302.919 samples/sec\n",
      "Training: epoch 3, total_step 1370, inference loss is 0.91, accuracy is 0.562500, time 293.333 samples/sec\n",
      "Training: epoch 3, total_step 1380, inference loss is 0.89, accuracy is 0.593750, time 305.824 samples/sec\n",
      "Training: epoch 3, total_step 1390, inference loss is 0.93, accuracy is 0.554688, time 309.859 samples/sec\n",
      "Training: epoch 3, total_step 1400, inference loss is 0.90, accuracy is 0.585938, time 291.156 samples/sec\n",
      "Training: epoch 3, total_step 1410, inference loss is 1.07, accuracy is 0.468750, time 287.207 samples/sec\n",
      "Training: epoch 3, total_step 1420, inference loss is 0.87, accuracy is 0.625000, time 295.861 samples/sec\n",
      "Training: epoch 3, total_step 1430, inference loss is 0.93, accuracy is 0.578125, time 294.438 samples/sec\n",
      "Training: epoch 3, total_step 1440, inference loss is 0.86, accuracy is 0.617188, time 287.945 samples/sec\n",
      "Training: epoch 3, total_step 1450, inference loss is 0.78, accuracy is 0.664062, time 298.812 samples/sec\n",
      "Training: epoch 3, total_step 1460, inference loss is 0.83, accuracy is 0.648438, time 277.266 samples/sec\n",
      "Training: epoch 3, total_step 1470, inference loss is 0.87, accuracy is 0.601562, time 294.887 samples/sec\n",
      "Training: epoch 3, total_step 1480, inference loss is 0.89, accuracy is 0.609375, time 288.077 samples/sec\n",
      "Training: epoch 3, total_step 1490, inference loss is 0.96, accuracy is 0.554688, time 297.907 samples/sec\n",
      "Training: epoch 3, total_step 1500, inference loss is 0.82, accuracy is 0.648438, time 304.248 samples/sec\n",
      "Training: epoch 3, total_step 1510, inference loss is 0.98, accuracy is 0.515625, time 288.731 samples/sec\n",
      "Training: epoch 3, total_step 1520, inference loss is 0.84, accuracy is 0.625000, time 288.433 samples/sec\n",
      "Training: epoch 3, total_step 1530, inference loss is 0.79, accuracy is 0.679688, time 288.298 samples/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 3, total_step 1540, inference loss is 0.91, accuracy is 0.562500, time 293.708 samples/sec\n",
      "Training: epoch 3, total_step 1550, inference loss is 0.84, accuracy is 0.679688, time 295.243 samples/sec\n",
      "End of epoch 3\n",
      "$$$$$$$$ Validation: epoch 3, accuracy is 0.657903\n",
      "Training: epoch 4, total_step 1560, inference loss is 0.86, accuracy is 0.632812, time 308.375 samples/sec\n",
      "Training: epoch 4, total_step 1570, inference loss is 0.87, accuracy is 0.617188, time 302.404 samples/sec\n",
      "Training: epoch 4, total_step 1580, inference loss is 0.93, accuracy is 0.593750, time 307.009 samples/sec\n",
      "Training: epoch 4, total_step 1590, inference loss is 0.98, accuracy is 0.539062, time 291.729 samples/sec\n",
      "Training: epoch 4, total_step 1600, inference loss is 1.00, accuracy is 0.539062, time 302.809 samples/sec\n",
      "Training: epoch 4, total_step 1610, inference loss is 0.81, accuracy is 0.687500, time 301.428 samples/sec\n",
      "Training: epoch 4, total_step 1620, inference loss is 0.82, accuracy is 0.632812, time 300.738 samples/sec\n",
      "Training: epoch 4, total_step 1630, inference loss is 1.00, accuracy is 0.578125, time 297.946 samples/sec\n",
      "Training: epoch 4, total_step 1640, inference loss is 0.97, accuracy is 0.546875, time 305.521 samples/sec\n",
      "Training: epoch 4, total_step 1650, inference loss is 1.02, accuracy is 0.515625, time 308.470 samples/sec\n",
      "Training: epoch 4, total_step 1660, inference loss is 0.89, accuracy is 0.601562, time 301.374 samples/sec\n",
      "Training: epoch 4, total_step 1670, inference loss is 0.84, accuracy is 0.609375, time 300.166 samples/sec\n",
      "Training: epoch 4, total_step 1680, inference loss is 0.80, accuracy is 0.679688, time 295.173 samples/sec\n",
      "Training: epoch 4, total_step 1690, inference loss is 0.82, accuracy is 0.664062, time 294.898 samples/sec\n",
      "Training: epoch 4, total_step 1700, inference loss is 0.77, accuracy is 0.625000, time 296.802 samples/sec\n",
      "Training: epoch 4, total_step 1710, inference loss is 0.91, accuracy is 0.570312, time 301.513 samples/sec\n",
      "Training: epoch 4, total_step 1720, inference loss is 0.89, accuracy is 0.625000, time 306.390 samples/sec\n",
      "Training: epoch 4, total_step 1730, inference loss is 0.85, accuracy is 0.570312, time 302.689 samples/sec\n",
      "Training: epoch 4, total_step 1740, inference loss is 0.84, accuracy is 0.632812, time 302.102 samples/sec\n",
      "Training: epoch 4, total_step 1750, inference loss is 1.01, accuracy is 0.539062, time 289.980 samples/sec\n",
      "Training: epoch 4, total_step 1760, inference loss is 0.83, accuracy is 0.593750, time 297.678 samples/sec\n",
      "Training: epoch 4, total_step 1770, inference loss is 0.95, accuracy is 0.585938, time 298.433 samples/sec\n",
      "Training: epoch 4, total_step 1780, inference loss is 0.90, accuracy is 0.593750, time 298.083 samples/sec\n",
      "Training: epoch 4, total_step 1790, inference loss is 0.84, accuracy is 0.671875, time 296.647 samples/sec\n",
      "Training: epoch 4, total_step 1800, inference loss is 0.90, accuracy is 0.554688, time 305.863 samples/sec\n",
      "Training: epoch 4, total_step 1810, inference loss is 0.87, accuracy is 0.617188, time 297.478 samples/sec\n",
      "Training: epoch 4, total_step 1820, inference loss is 0.97, accuracy is 0.531250, time 305.731 samples/sec\n",
      "Training: epoch 4, total_step 1830, inference loss is 0.94, accuracy is 0.562500, time 303.171 samples/sec\n",
      "Training: epoch 4, total_step 1840, inference loss is 0.83, accuracy is 0.671875, time 300.459 samples/sec\n",
      "Training: epoch 4, total_step 1850, inference loss is 0.91, accuracy is 0.601562, time 283.892 samples/sec\n",
      "Training: epoch 4, total_step 1860, inference loss is 0.88, accuracy is 0.617188, time 292.256 samples/sec\n",
      "Training: epoch 4, total_step 1870, inference loss is 0.83, accuracy is 0.609375, time 313.416 samples/sec\n",
      "Training: epoch 4, total_step 1880, inference loss is 0.87, accuracy is 0.632812, time 301.066 samples/sec\n",
      "Training: epoch 4, total_step 1890, inference loss is 0.97, accuracy is 0.570312, time 299.910 samples/sec\n",
      "Training: epoch 4, total_step 1900, inference loss is 0.81, accuracy is 0.648438, time 295.608 samples/sec\n",
      "Training: epoch 4, total_step 1910, inference loss is 0.87, accuracy is 0.648438, time 306.725 samples/sec\n",
      "Training: epoch 4, total_step 1920, inference loss is 0.85, accuracy is 0.617188, time 306.385 samples/sec\n",
      "Training: epoch 4, total_step 1930, inference loss is 0.91, accuracy is 0.625000, time 302.156 samples/sec\n",
      "Training: epoch 4, total_step 1940, inference loss is 0.88, accuracy is 0.625000, time 281.298 samples/sec\n",
      "End of epoch 4\n",
      "$$$$$$$$ Validation: epoch 4, accuracy is 0.723183\n",
      "Training: epoch 5, total_step 1950, inference loss is 0.91, accuracy is 0.546875, time 277.456 samples/sec\n",
      "Training: epoch 5, total_step 1960, inference loss is 0.83, accuracy is 0.601562, time 298.960 samples/sec\n",
      "Training: epoch 5, total_step 1970, inference loss is 0.73, accuracy is 0.695312, time 299.691 samples/sec\n",
      "Training: epoch 5, total_step 1980, inference loss is 0.85, accuracy is 0.656250, time 309.729 samples/sec\n",
      "Training: epoch 5, total_step 1990, inference loss is 0.97, accuracy is 0.554688, time 299.905 samples/sec\n",
      "Training: epoch 5, total_step 2000, inference loss is 0.95, accuracy is 0.578125, time 285.376 samples/sec\n",
      "Training: epoch 5, total_step 2010, inference loss is 0.98, accuracy is 0.593750, time 300.327 samples/sec\n",
      "Training: epoch 5, total_step 2020, inference loss is 0.88, accuracy is 0.601562, time 301.135 samples/sec\n",
      "Training: epoch 5, total_step 2030, inference loss is 1.03, accuracy is 0.523438, time 274.440 samples/sec\n",
      "Training: epoch 5, total_step 2040, inference loss is 0.92, accuracy is 0.632812, time 302.844 samples/sec\n",
      "Training: epoch 5, total_step 2050, inference loss is 0.90, accuracy is 0.570312, time 303.450 samples/sec\n",
      "Training: epoch 5, total_step 2060, inference loss is 0.91, accuracy is 0.648438, time 270.594 samples/sec\n",
      "Training: epoch 5, total_step 2070, inference loss is 0.87, accuracy is 0.585938, time 284.250 samples/sec\n",
      "Training: epoch 5, total_step 2080, inference loss is 0.83, accuracy is 0.632812, time 282.860 samples/sec\n",
      "Training: epoch 5, total_step 2090, inference loss is 0.92, accuracy is 0.562500, time 294.286 samples/sec\n",
      "Training: epoch 5, total_step 2100, inference loss is 0.88, accuracy is 0.585938, time 292.651 samples/sec\n",
      "Training: epoch 5, total_step 2110, inference loss is 0.91, accuracy is 0.617188, time 311.784 samples/sec\n",
      "Training: epoch 5, total_step 2120, inference loss is 0.86, accuracy is 0.656250, time 294.113 samples/sec\n",
      "Training: epoch 5, total_step 2130, inference loss is 0.98, accuracy is 0.546875, time 306.785 samples/sec\n",
      "Training: epoch 5, total_step 2140, inference loss is 0.88, accuracy is 0.578125, time 304.492 samples/sec\n",
      "Training: epoch 5, total_step 2150, inference loss is 0.90, accuracy is 0.578125, time 290.773 samples/sec\n",
      "Training: epoch 5, total_step 2160, inference loss is 0.89, accuracy is 0.640625, time 300.923 samples/sec\n",
      "Training: epoch 5, total_step 2170, inference loss is 0.78, accuracy is 0.687500, time 293.177 samples/sec\n",
      "Training: epoch 5, total_step 2180, inference loss is 0.88, accuracy is 0.593750, time 301.991 samples/sec\n",
      "Training: epoch 5, total_step 2190, inference loss is 0.85, accuracy is 0.609375, time 294.697 samples/sec\n",
      "Training: epoch 5, total_step 2200, inference loss is 0.73, accuracy is 0.664062, time 285.129 samples/sec\n",
      "Training: epoch 5, total_step 2210, inference loss is 0.82, accuracy is 0.640625, time 295.162 samples/sec\n",
      "Training: epoch 5, total_step 2220, inference loss is 0.89, accuracy is 0.640625, time 293.939 samples/sec\n",
      "Training: epoch 5, total_step 2230, inference loss is 0.90, accuracy is 0.617188, time 289.340 samples/sec\n",
      "Training: epoch 5, total_step 2240, inference loss is 0.89, accuracy is 0.531250, time 285.642 samples/sec\n",
      "Training: epoch 5, total_step 2250, inference loss is 0.97, accuracy is 0.601562, time 316.317 samples/sec\n",
      "Training: epoch 5, total_step 2260, inference loss is 0.88, accuracy is 0.578125, time 294.589 samples/sec\n",
      "Training: epoch 5, total_step 2270, inference loss is 0.76, accuracy is 0.710938, time 293.719 samples/sec\n",
      "Training: epoch 5, total_step 2280, inference loss is 0.89, accuracy is 0.625000, time 286.672 samples/sec\n",
      "Training: epoch 5, total_step 2290, inference loss is 0.88, accuracy is 0.640625, time 301.135 samples/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 5, total_step 2300, inference loss is 0.96, accuracy is 0.578125, time 299.199 samples/sec\n",
      "Training: epoch 5, total_step 2310, inference loss is 0.84, accuracy is 0.648438, time 286.085 samples/sec\n",
      "Training: epoch 5, total_step 2320, inference loss is 0.81, accuracy is 0.632812, time 291.711 samples/sec\n",
      "Training: epoch 5, total_step 2330, inference loss is 0.79, accuracy is 0.671875, time 278.380 samples/sec\n",
      "End of epoch 5\n",
      "$$$$$$$$ Validation: epoch 5, accuracy is 0.733665\n",
      "Training: epoch 6, total_step 2340, inference loss is 0.86, accuracy is 0.585938, time 312.012 samples/sec\n",
      "Training: epoch 6, total_step 2350, inference loss is 0.96, accuracy is 0.578125, time 297.012 samples/sec\n",
      "Training: epoch 6, total_step 2360, inference loss is 0.83, accuracy is 0.679688, time 313.450 samples/sec\n",
      "Training: epoch 6, total_step 2370, inference loss is 0.83, accuracy is 0.609375, time 305.913 samples/sec\n",
      "Training: epoch 6, total_step 2380, inference loss is 0.78, accuracy is 0.664062, time 293.542 samples/sec\n",
      "Training: epoch 6, total_step 2390, inference loss is 0.86, accuracy is 0.617188, time 288.882 samples/sec\n",
      "Training: epoch 6, total_step 2400, inference loss is 0.90, accuracy is 0.617188, time 275.297 samples/sec\n",
      "Training: epoch 6, total_step 2410, inference loss is 0.86, accuracy is 0.640625, time 303.891 samples/sec\n",
      "Training: epoch 6, total_step 2420, inference loss is 0.83, accuracy is 0.617188, time 234.929 samples/sec\n",
      "Training: epoch 6, total_step 2430, inference loss is 0.89, accuracy is 0.593750, time 239.834 samples/sec\n",
      "Training: epoch 6, total_step 2440, inference loss is 0.95, accuracy is 0.609375, time 237.746 samples/sec\n",
      "Training: epoch 6, total_step 2450, inference loss is 0.81, accuracy is 0.593750, time 235.693 samples/sec\n",
      "Training: epoch 6, total_step 2460, inference loss is 0.83, accuracy is 0.671875, time 239.294 samples/sec\n",
      "Training: epoch 6, total_step 2470, inference loss is 0.89, accuracy is 0.562500, time 236.259 samples/sec\n",
      "Training: epoch 6, total_step 2480, inference loss is 0.86, accuracy is 0.601562, time 240.340 samples/sec\n",
      "Training: epoch 6, total_step 2490, inference loss is 0.89, accuracy is 0.609375, time 238.899 samples/sec\n",
      "Training: epoch 6, total_step 2500, inference loss is 0.82, accuracy is 0.703125, time 234.143 samples/sec\n",
      "Training: epoch 6, total_step 2510, inference loss is 0.98, accuracy is 0.539062, time 299.555 samples/sec\n",
      "Training: epoch 6, total_step 2520, inference loss is 0.95, accuracy is 0.585938, time 300.517 samples/sec\n",
      "Training: epoch 6, total_step 2530, inference loss is 0.84, accuracy is 0.648438, time 286.194 samples/sec\n",
      "Training: epoch 6, total_step 2540, inference loss is 0.82, accuracy is 0.585938, time 292.501 samples/sec\n",
      "Training: epoch 6, total_step 2550, inference loss is 0.91, accuracy is 0.593750, time 285.814 samples/sec\n",
      "Training: epoch 6, total_step 2560, inference loss is 0.91, accuracy is 0.640625, time 281.157 samples/sec\n",
      "Training: epoch 6, total_step 2570, inference loss is 0.90, accuracy is 0.570312, time 291.659 samples/sec\n",
      "Training: epoch 6, total_step 2580, inference loss is 0.83, accuracy is 0.617188, time 309.217 samples/sec\n",
      "Training: epoch 6, total_step 2590, inference loss is 0.92, accuracy is 0.593750, time 293.723 samples/sec\n",
      "Training: epoch 6, total_step 2600, inference loss is 0.94, accuracy is 0.554688, time 295.061 samples/sec\n",
      "Training: epoch 6, total_step 2610, inference loss is 0.98, accuracy is 0.585938, time 291.636 samples/sec\n",
      "Training: epoch 6, total_step 2620, inference loss is 0.82, accuracy is 0.640625, time 300.862 samples/sec\n",
      "Training: epoch 6, total_step 2630, inference loss is 0.93, accuracy is 0.585938, time 298.905 samples/sec\n",
      "Training: epoch 6, total_step 2640, inference loss is 0.79, accuracy is 0.695312, time 305.639 samples/sec\n",
      "Training: epoch 6, total_step 2650, inference loss is 0.90, accuracy is 0.617188, time 291.640 samples/sec\n",
      "Training: epoch 6, total_step 2660, inference loss is 0.94, accuracy is 0.570312, time 306.437 samples/sec\n",
      "Training: epoch 6, total_step 2670, inference loss is 0.78, accuracy is 0.687500, time 300.511 samples/sec\n",
      "Training: epoch 6, total_step 2680, inference loss is 0.79, accuracy is 0.687500, time 303.757 samples/sec\n",
      "Training: epoch 6, total_step 2690, inference loss is 0.78, accuracy is 0.679688, time 315.399 samples/sec\n",
      "Training: epoch 6, total_step 2700, inference loss is 0.88, accuracy is 0.625000, time 297.646 samples/sec\n",
      "Training: epoch 6, total_step 2710, inference loss is 0.87, accuracy is 0.578125, time 295.779 samples/sec\n",
      "Training: epoch 6, total_step 2720, inference loss is 0.82, accuracy is 0.648438, time 299.522 samples/sec\n",
      "End of epoch 6\n",
      "$$$$$$$$ Validation: epoch 6, accuracy is 0.724236\n",
      "Training: epoch 7, total_step 2730, inference loss is 0.86, accuracy is 0.632812, time 298.033 samples/sec\n",
      "Training: epoch 7, total_step 2740, inference loss is 0.86, accuracy is 0.601562, time 306.912 samples/sec\n",
      "Training: epoch 7, total_step 2750, inference loss is 0.86, accuracy is 0.625000, time 302.408 samples/sec\n",
      "Training: epoch 7, total_step 2760, inference loss is 0.94, accuracy is 0.578125, time 290.519 samples/sec\n",
      "Training: epoch 7, total_step 2770, inference loss is 0.87, accuracy is 0.656250, time 298.966 samples/sec\n",
      "Training: epoch 7, total_step 2780, inference loss is 0.84, accuracy is 0.664062, time 303.194 samples/sec\n",
      "Training: epoch 7, total_step 2790, inference loss is 0.80, accuracy is 0.703125, time 295.990 samples/sec\n",
      "Training: epoch 7, total_step 2800, inference loss is 0.80, accuracy is 0.710938, time 299.479 samples/sec\n",
      "Training: epoch 7, total_step 2810, inference loss is 0.79, accuracy is 0.609375, time 291.444 samples/sec\n",
      "Training: epoch 7, total_step 2820, inference loss is 0.86, accuracy is 0.601562, time 298.311 samples/sec\n",
      "Training: epoch 7, total_step 2830, inference loss is 0.93, accuracy is 0.570312, time 296.592 samples/sec\n",
      "Training: epoch 7, total_step 2840, inference loss is 0.87, accuracy is 0.632812, time 294.726 samples/sec\n",
      "Training: epoch 7, total_step 2850, inference loss is 0.85, accuracy is 0.640625, time 292.649 samples/sec\n",
      "Training: epoch 7, total_step 2860, inference loss is 0.86, accuracy is 0.648438, time 295.453 samples/sec\n",
      "Training: epoch 7, total_step 2870, inference loss is 0.76, accuracy is 0.734375, time 305.635 samples/sec\n",
      "Training: epoch 7, total_step 2880, inference loss is 0.84, accuracy is 0.640625, time 296.954 samples/sec\n",
      "Training: epoch 7, total_step 2890, inference loss is 0.83, accuracy is 0.679688, time 289.924 samples/sec\n",
      "Training: epoch 7, total_step 2900, inference loss is 0.89, accuracy is 0.593750, time 296.515 samples/sec\n",
      "Training: epoch 7, total_step 2910, inference loss is 0.79, accuracy is 0.656250, time 296.345 samples/sec\n",
      "Training: epoch 7, total_step 2920, inference loss is 0.90, accuracy is 0.562500, time 298.011 samples/sec\n",
      "Training: epoch 7, total_step 2930, inference loss is 0.96, accuracy is 0.585938, time 299.229 samples/sec\n",
      "Training: epoch 7, total_step 2940, inference loss is 0.77, accuracy is 0.703125, time 297.822 samples/sec\n",
      "Training: epoch 7, total_step 2950, inference loss is 0.75, accuracy is 0.679688, time 303.882 samples/sec\n",
      "Training: epoch 7, total_step 2960, inference loss is 0.81, accuracy is 0.664062, time 299.392 samples/sec\n",
      "Training: epoch 7, total_step 2970, inference loss is 0.74, accuracy is 0.710938, time 309.227 samples/sec\n",
      "Training: epoch 7, total_step 2980, inference loss is 0.93, accuracy is 0.593750, time 290.259 samples/sec\n",
      "Training: epoch 7, total_step 2990, inference loss is 0.84, accuracy is 0.656250, time 295.931 samples/sec\n",
      "Training: epoch 7, total_step 3000, inference loss is 0.88, accuracy is 0.664062, time 307.092 samples/sec\n",
      "Training: epoch 7, total_step 3010, inference loss is 0.75, accuracy is 0.710938, time 301.643 samples/sec\n",
      "Training: epoch 7, total_step 3020, inference loss is 0.93, accuracy is 0.578125, time 302.365 samples/sec\n",
      "Training: epoch 7, total_step 3030, inference loss is 0.85, accuracy is 0.617188, time 304.390 samples/sec\n",
      "Training: epoch 7, total_step 3040, inference loss is 0.91, accuracy is 0.593750, time 296.265 samples/sec\n",
      "Training: epoch 7, total_step 3050, inference loss is 0.91, accuracy is 0.593750, time 295.781 samples/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 7, total_step 3060, inference loss is 0.68, accuracy is 0.742188, time 297.474 samples/sec\n",
      "Training: epoch 7, total_step 3070, inference loss is 0.86, accuracy is 0.593750, time 303.640 samples/sec\n",
      "Training: epoch 7, total_step 3080, inference loss is 0.86, accuracy is 0.632812, time 291.187 samples/sec\n",
      "Training: epoch 7, total_step 3090, inference loss is 0.90, accuracy is 0.554688, time 292.975 samples/sec\n",
      "Training: epoch 7, total_step 3100, inference loss is 0.91, accuracy is 0.578125, time 297.230 samples/sec\n",
      "Training: epoch 7, total_step 3110, inference loss is 0.88, accuracy is 0.625000, time 299.767 samples/sec\n",
      "End of epoch 7\n",
      "$$$$$$$$ Validation: epoch 7, accuracy is 0.722534\n",
      "Training: epoch 8, total_step 3120, inference loss is 0.85, accuracy is 0.648438, time 295.369 samples/sec\n",
      "Training: epoch 8, total_step 3130, inference loss is 0.77, accuracy is 0.664062, time 302.460 samples/sec\n",
      "Training: epoch 8, total_step 3140, inference loss is 0.75, accuracy is 0.687500, time 303.047 samples/sec\n",
      "Training: epoch 8, total_step 3150, inference loss is 0.83, accuracy is 0.640625, time 303.640 samples/sec\n",
      "Training: epoch 8, total_step 3160, inference loss is 0.83, accuracy is 0.648438, time 292.475 samples/sec\n",
      "Training: epoch 8, total_step 3170, inference loss is 0.93, accuracy is 0.585938, time 296.209 samples/sec\n",
      "Training: epoch 8, total_step 3180, inference loss is 0.88, accuracy is 0.625000, time 302.581 samples/sec\n",
      "Training: epoch 8, total_step 3190, inference loss is 0.93, accuracy is 0.609375, time 294.400 samples/sec\n",
      "Training: epoch 8, total_step 3200, inference loss is 0.83, accuracy is 0.632812, time 279.362 samples/sec\n",
      "Training: epoch 8, total_step 3210, inference loss is 0.85, accuracy is 0.703125, time 298.666 samples/sec\n",
      "Training: epoch 8, total_step 3220, inference loss is 0.81, accuracy is 0.664062, time 302.471 samples/sec\n",
      "Training: epoch 8, total_step 3230, inference loss is 0.76, accuracy is 0.671875, time 306.694 samples/sec\n",
      "Training: epoch 8, total_step 3240, inference loss is 0.85, accuracy is 0.585938, time 308.267 samples/sec\n",
      "Training: epoch 8, total_step 3250, inference loss is 0.79, accuracy is 0.695312, time 296.139 samples/sec\n",
      "Training: epoch 8, total_step 3260, inference loss is 0.83, accuracy is 0.632812, time 308.056 samples/sec\n",
      "Training: epoch 8, total_step 3270, inference loss is 0.92, accuracy is 0.585938, time 292.284 samples/sec\n",
      "Training: epoch 8, total_step 3280, inference loss is 0.86, accuracy is 0.562500, time 274.980 samples/sec\n",
      "Training: epoch 8, total_step 3290, inference loss is 1.02, accuracy is 0.539062, time 266.126 samples/sec\n",
      "Training: epoch 8, total_step 3300, inference loss is 0.81, accuracy is 0.648438, time 237.618 samples/sec\n",
      "Training: epoch 8, total_step 3310, inference loss is 0.83, accuracy is 0.625000, time 243.489 samples/sec\n",
      "Training: epoch 8, total_step 3320, inference loss is 0.83, accuracy is 0.601562, time 233.348 samples/sec\n",
      "Training: epoch 8, total_step 3330, inference loss is 0.79, accuracy is 0.632812, time 237.072 samples/sec\n",
      "Training: epoch 8, total_step 3340, inference loss is 0.88, accuracy is 0.609375, time 237.990 samples/sec\n",
      "Training: epoch 8, total_step 3350, inference loss is 0.94, accuracy is 0.570312, time 242.393 samples/sec\n",
      "Training: epoch 8, total_step 3360, inference loss is 0.93, accuracy is 0.632812, time 239.416 samples/sec\n",
      "Training: epoch 8, total_step 3370, inference loss is 0.81, accuracy is 0.671875, time 237.941 samples/sec\n",
      "Training: epoch 8, total_step 3380, inference loss is 0.89, accuracy is 0.554688, time 234.670 samples/sec\n",
      "Training: epoch 8, total_step 3390, inference loss is 0.88, accuracy is 0.632812, time 251.332 samples/sec\n",
      "Training: epoch 8, total_step 3400, inference loss is 0.77, accuracy is 0.679688, time 258.538 samples/sec\n",
      "Training: epoch 8, total_step 3410, inference loss is 0.79, accuracy is 0.687500, time 265.875 samples/sec\n",
      "Training: epoch 8, total_step 3420, inference loss is 0.88, accuracy is 0.585938, time 266.737 samples/sec\n",
      "Training: epoch 8, total_step 3430, inference loss is 0.81, accuracy is 0.656250, time 232.874 samples/sec\n",
      "Training: epoch 8, total_step 3440, inference loss is 0.78, accuracy is 0.656250, time 241.568 samples/sec\n",
      "Training: epoch 8, total_step 3450, inference loss is 0.79, accuracy is 0.656250, time 274.847 samples/sec\n",
      "Training: epoch 8, total_step 3460, inference loss is 0.89, accuracy is 0.570312, time 246.525 samples/sec\n",
      "Training: epoch 8, total_step 3470, inference loss is 0.92, accuracy is 0.593750, time 258.396 samples/sec\n",
      "Training: epoch 8, total_step 3480, inference loss is 0.98, accuracy is 0.546875, time 252.437 samples/sec\n",
      "Training: epoch 8, total_step 3490, inference loss is 0.86, accuracy is 0.632812, time 258.850 samples/sec\n",
      "Training: epoch 8, total_step 3500, inference loss is 0.85, accuracy is 0.631148, time 277.051 samples/sec\n",
      "End of epoch 8\n",
      "$$$$$$$$ Validation: epoch 8, accuracy is 0.725718\n",
      "Training: epoch 9, total_step 3510, inference loss is 0.85, accuracy is 0.648438, time 269.962 samples/sec\n",
      "Training: epoch 9, total_step 3520, inference loss is 0.82, accuracy is 0.648438, time 274.645 samples/sec\n",
      "Training: epoch 9, total_step 3530, inference loss is 0.81, accuracy is 0.664062, time 262.226 samples/sec\n",
      "Training: epoch 9, total_step 3540, inference loss is 0.85, accuracy is 0.617188, time 278.090 samples/sec\n",
      "Training: epoch 9, total_step 3550, inference loss is 0.82, accuracy is 0.632812, time 267.399 samples/sec\n",
      "Training: epoch 9, total_step 3560, inference loss is 0.89, accuracy is 0.625000, time 257.547 samples/sec\n",
      "Training: epoch 9, total_step 3570, inference loss is 0.91, accuracy is 0.601562, time 256.906 samples/sec\n",
      "Training: epoch 9, total_step 3580, inference loss is 0.82, accuracy is 0.664062, time 277.137 samples/sec\n",
      "Training: epoch 9, total_step 3590, inference loss is 0.82, accuracy is 0.640625, time 271.945 samples/sec\n",
      "Training: epoch 9, total_step 3600, inference loss is 0.87, accuracy is 0.601562, time 256.310 samples/sec\n",
      "Training: epoch 9, total_step 3610, inference loss is 0.75, accuracy is 0.750000, time 273.414 samples/sec\n",
      "Training: epoch 9, total_step 3620, inference loss is 0.80, accuracy is 0.617188, time 258.853 samples/sec\n",
      "Training: epoch 9, total_step 3630, inference loss is 0.81, accuracy is 0.609375, time 263.237 samples/sec\n",
      "Training: epoch 9, total_step 3640, inference loss is 0.89, accuracy is 0.593750, time 268.686 samples/sec\n",
      "Training: epoch 9, total_step 3650, inference loss is 0.92, accuracy is 0.617188, time 257.611 samples/sec\n",
      "Training: epoch 9, total_step 3660, inference loss is 0.79, accuracy is 0.679688, time 272.564 samples/sec\n",
      "Training: epoch 9, total_step 3670, inference loss is 0.84, accuracy is 0.578125, time 263.645 samples/sec\n",
      "Training: epoch 9, total_step 3680, inference loss is 0.91, accuracy is 0.625000, time 249.918 samples/sec\n",
      "Training: epoch 9, total_step 3690, inference loss is 0.91, accuracy is 0.632812, time 245.025 samples/sec\n",
      "Training: epoch 9, total_step 3700, inference loss is 0.79, accuracy is 0.640625, time 255.763 samples/sec\n",
      "Training: epoch 9, total_step 3710, inference loss is 0.85, accuracy is 0.617188, time 254.155 samples/sec\n",
      "Training: epoch 9, total_step 3720, inference loss is 0.83, accuracy is 0.625000, time 238.772 samples/sec\n",
      "Training: epoch 9, total_step 3730, inference loss is 1.09, accuracy is 0.554688, time 242.767 samples/sec\n",
      "Training: epoch 9, total_step 3740, inference loss is 0.92, accuracy is 0.617188, time 249.620 samples/sec\n",
      "Training: epoch 9, total_step 3750, inference loss is 0.81, accuracy is 0.710938, time 243.684 samples/sec\n",
      "Training: epoch 9, total_step 3760, inference loss is 0.84, accuracy is 0.617188, time 259.098 samples/sec\n",
      "Training: epoch 9, total_step 3770, inference loss is 0.88, accuracy is 0.585938, time 258.386 samples/sec\n",
      "Training: epoch 9, total_step 3780, inference loss is 0.87, accuracy is 0.640625, time 236.800 samples/sec\n",
      "Training: epoch 9, total_step 3790, inference loss is 0.96, accuracy is 0.531250, time 241.834 samples/sec\n",
      "Training: epoch 9, total_step 3800, inference loss is 0.83, accuracy is 0.679688, time 239.649 samples/sec\n",
      "Training: epoch 9, total_step 3810, inference loss is 0.88, accuracy is 0.656250, time 234.280 samples/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 9, total_step 3820, inference loss is 0.90, accuracy is 0.601562, time 240.750 samples/sec\n",
      "Training: epoch 9, total_step 3830, inference loss is 0.86, accuracy is 0.664062, time 241.750 samples/sec\n",
      "Training: epoch 9, total_step 3840, inference loss is 0.91, accuracy is 0.546875, time 233.540 samples/sec\n",
      "Training: epoch 9, total_step 3850, inference loss is 0.82, accuracy is 0.632812, time 240.865 samples/sec\n",
      "Training: epoch 9, total_step 3860, inference loss is 0.90, accuracy is 0.570312, time 234.743 samples/sec\n",
      "Training: epoch 9, total_step 3870, inference loss is 0.83, accuracy is 0.695312, time 298.041 samples/sec\n",
      "Training: epoch 9, total_step 3880, inference loss is 0.93, accuracy is 0.632812, time 294.203 samples/sec\n",
      "End of epoch 9\n",
      "$$$$$$$$ Validation: epoch 9, accuracy is 0.729134\n"
     ]
    }
   ],
   "source": [
    "img_verify_flag = False # set to false during actual training\n",
    "count = 0\n",
    "validation_result = []\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(config.NUM_EPOCH):\n",
    "    \n",
    "    sess.run(iterator_train.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            images_train, labels_train = sess.run(next_element_train)\n",
    "            #images_train, images_show, labels_train = sess.run(next_element_train) # for dataset debug\n",
    "            if img_verify_flag: # for dataset debug\n",
    "                img = Image.fromarray(images_show[0,...], 'RGB')\n",
    "                img.show()\n",
    "                exit(1)\n",
    "            feed_dict = {features_ph: images_train, labels_ph: labels_train}            \n",
    "            embTrain, logitTrain, inferenceLossTrain, accTrain, _, _ = \\\n",
    "                sess.run([embeddings, logit, inference_loss, acc, train_op, inc_op],\n",
    "                          feed_dict=feed_dict,\n",
    "                          options=config_pb2.RunOptions(report_tensor_allocations_upon_oom=True))\n",
    "            end = time.time()\n",
    "            pre_sec = config.BATCH_SIZE/(end - start)\n",
    "            \n",
    "            if count > 0 and count % config.Update_Interval == 0:\n",
    "                # logging\n",
    "                print('Training: epoch %d, total_step %d, inference loss is %.2f, '\n",
    "                      'accuracy is %.6f, time %.3f samples/sec' %\n",
    "                          (i, count, inferenceLossTrain, accTrain,pre_sec))\n",
    "                log_file.write('Training: epoch %d, total_step %d, inference_loss %.2f, '\n",
    "                               'accuracy %.6f, time %.3f samples/sec' %\n",
    "                               (i, count, inferenceLossTrain, accTrain,pre_sec) + '\\n')\n",
    "                log_file.flush()\n",
    "                \n",
    "                # save summary\n",
    "                summary_op_val = sess.run(summary_op, feed_dict=feed_dict)\n",
    "                summary.add_summary(summary_op_val, count)\n",
    "                \n",
    "                #print(embTrain)\n",
    "                #print(logitTrain)\n",
    "                #print(inferenceLossTrain)\n",
    "                #print(labels_train)\n",
    "                #print(images_train)\n",
    "            count += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of epoch %d\" % i)\n",
    "            break\n",
    "    \n",
    "    # save check points\n",
    "    ckpt_filename = config.PREFIX+'_{:d}'.format(i) + '.ckpt'\n",
    "    ckpt_filename = os.path.join(checkpointsPath, ckpt_filename)\n",
    "    saver.save(sess, ckpt_filename)\n",
    "    \n",
    "            \n",
    "    # do validation\n",
    "    accVal = []\n",
    "    predVal = []\n",
    "    labelVal = np.array([])\n",
    "    sess.run(iterator_val.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            images_val, labels_val = sess.run(next_element_val)\n",
    "            feed_dict = {features_val_ph: images_val, labels_val_ph: labels_val}\n",
    "            acc_tmp, pred_tmp = \\\n",
    "                sess.run([acc_val, pred_val],\n",
    "                          feed_dict=feed_dict,\n",
    "                          options=config_pb2.RunOptions(report_tensor_allocations_upon_oom=True))                        \n",
    "            accVal += [acc_tmp]\n",
    "            #print(accVal)\n",
    "            \n",
    "            if type(predVal) == type([]):\n",
    "                predVal = pred_tmp\n",
    "            else:\n",
    "                predVal = np.append(predVal, pred_tmp, axis=0)\n",
    "            labelVal = np.append(labelVal, labels_val)\n",
    "            \n",
    "            #print(predVal)\n",
    "            #print(labelVal)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break    \n",
    "    accVal = np.mean(accVal)\n",
    "    print('$$$$$$$$ Validation: epoch %d, accuracy is %.6f' % (i, accVal))\n",
    "    log_file.write('Validation: epoch %d, accuracy %.6f' % (i, accVal) + '\\n')\n",
    "    log_file.flush()\n",
    "    \n",
    "    # save validation results\n",
    "    validation_result += [{'label': labelVal, 'pred': predVal}]\n",
    "    with open(checkpointsPath+'/'+config.PREFIX+'_val_result.pkl', 'wb') as f:\n",
    "        pickle.dump(validation_result, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {features_ph: feature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "emb_out=sess.run([embedding],feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = tf.cast(0.1, dtype=tf.bool)\n",
    "aaa=sess.run(aa)\n",
    "print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(net),net[0].shape,net[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = SpoofDenseNet.build(net, [128,64,16], True, tf.nn.relu, config.Regularizer['CoALBP_GREY'], config.Initializer, scope=\"firstTry1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[1].shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.fromarray(images[0,...], 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features['image/height'][0])\n",
    "print(features['image/width'][0])\n",
    "print(features['image/class/text'][0])\n",
    "print(features['image/class/label'][0])\n",
    "print(len(features['image/encoded'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.image.decode_jpeg(features['image/encoded'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sess.run(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(name='global_step', initial_value=0, trainable=False)\n",
    "inc_op = tf.assign_add(global_step, 1, name='increment_global_step')\n",
    "lr = tf.train.piecewise_constant(global_step, boundaries=config.Opt_lr_steps, values=config.Opt_lr, name='lr_schedule')\n",
    "# define the optimize method\n",
    "opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=config.Opt_momentum)\n",
    "# get train op\n",
    "#grads = opt.compute_gradients(inference_loss)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):        \n",
    "    #train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "    train_op = opt.minimize(inference_loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training')\n",
    "x = tf.placeholder(tf.float32, [None, 1], 'x')\n",
    "y = tf.layers.batch_normalization(x, training=True)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    y = tf.identity(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "x_1 = [[-10], [0], [10]]\n",
    "x_2 = [[-10]]\n",
    "for _ in range(1000):\n",
    "    y_1 = sess.run(y, feed_dict={x: x_1, is_training: False})\n",
    "y_2 = sess.run(y, feed_dict={x: x_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
